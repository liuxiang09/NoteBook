# 《LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS》

## 1. Introduction

- 许多自然语言处理应用依赖于将**一个**大规模预训练语言模型适配到**多个**下游任务中。这种适配通常通过**完整微调（fine-tuning）**来实现，即更新预训练模型的所有参数。
- 完整微调的主要缺点是，新模型拥有与原始模型**相同**的参数数量。对于参数量高达1750亿的GPT-3来说，其部署成本变得极其高昂。
- 为了解决这一问题，研究者们尝试**仅调整部分参数**或**为新任务学习外部模块**。然而，现有技术通常会引入**推理延迟**，例如扩展模型深度或减少可用的序列长度。此外，更重要的是，这些方法往往无法达到微调基线的性能。
- 
