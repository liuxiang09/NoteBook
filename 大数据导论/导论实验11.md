## 实验 11：SQL 的查重与去重

### 一、 实验内容

一般来说，数据提质有两个主要的目标，一是解决数据质量问题，二是让数 据更适合做挖掘。面向不同的目标，由于还存在很多细节的情形，因此也存在相 应的解决方式和方法。其中，为了解决数据的唯一性问题（例如不同来源的数据 出现重复的情况），需要去除重复记录，只保留其中一条记录。  
	
本次实验利用 SQL 语句的 select 及其中的 distinct,查询 student 表格中重复 的电话号码，将电话号码重复的保存其中任意一条记录，即删除其它重复记录。  

### 二、 实验目标

- 掌握基本 SQL 查询语句  

- 掌握 SQL 中 distinct 的用法  

- 掌握 SQL 中的去重方法   

### 三、 实验代码

```sql
select class, COUNT(sno) from student group by class having count(class) > 1;

delete from student 
	where class in (select  class	from student group by class having count(class) > 1)
	and sno not in (select min(sno) from student group by class having count(*) > 1);
```



## 实验 12：网络蜘蛛的搜索与应用

### 一、 实验内容 

数据最丰富的的莫过于互联网，然而面对浩如烟海、看似在手边的数据，如 何有效获取也是存在技术问题的。有人说最简单的方法是通过搜索引擎获得网页， 再下载到本地，分类进行存储。少量基于主题的数据当然可以这么做，但大量基 于多个主题甚至于海量数据获取，采用这种方法效率就太低了。面对这种情况， 普通采用的有效方式即数据爬取。 本实验主要是搜索并下载某个网络蜘蛛，了解其爬取原理，配置并运行网络 蜘蛛，并完成一个简单的数据爬取实例。

###  二、 实验目标 

- 掌握网络蜘蛛的基本爬取原理 

- 掌握网络蜘蛛的工作流程 

- 掌握网络蜘蛛的简单应用 

### 三、 实验代码

```python
import requests
from pyquery import PyQuery as pq
import json
import pandas as pd

columns = ['title', 'msg', 'price', 'per_meter']


#   标题      信息      价格

# pyquery空格可以代表子孙节点

# 爬取某网页
def get_a_page(url):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36"
    }
    # 请求对象的定制
    result = requests.get(url, headers=headers)
    doc = pq(result.text)  # 实例化
    ul = doc('.sellListContent')  # 我们发现存储所有房价的信息都在 <ul class="sellListContent" log-mod="list"> 中，首先获取ul内容
    divs = ul.children('.clear .info.clear').items()  # ul中单个房子的信息都存储在<li class="clear">中；
    # 其中<div class="info clear">下的信息是需要的，空格代表子孙节点
    count = 0  # 计数器
    titles = []  # 存储标题3
    places = []  # 存储地址
    msgs = []  # 其他信息
    prices = []  # 房价
    per_meters = []  # 均价
    for div in divs:
        count += 1  # 计数器+1
        # 标题信息在 <div class="title">中的
        # <a class="VIEWDATA CLICKDATA maidian-detail" title="槐安路 三室两卫...
        title = div.children('.title a').text()
        # 地址信息在<div class="address">中的<div class="flood">
        # 中的<div class="positionInfo">中的<a href="https://sjz.ke.com/xiaoqu/3211056036908/">
        place = div.children('.address .flood .positionInfo a').text()
        # 其他信息在<div class="address">中的<div class="houseInfo">
        msg = div.children('.address .houseInfo').text()
        # 价格在<div class="address">中的<div class="priceInfo">中的
        # 中的<div class="totalPrice totalPrice2">中的<span>185</span>
        price = div.children('.address .priceInfo .totalPrice span').text()
        # 单位价格在<div class="address">中的<div class="priceInfo">
        # 中的 <div class="unitPrice" data-hid="101113853969" data-price="">中的 <span>15,871元/平</span>
        per_meter = div.children('.address .priceInfo .unitPrice span').text()
        # 使用字典进行存储
        dict = {
            'title': title,
            'place': place,
            'msg': msg,
            'price': price,
            'per_meter': per_meter
        }
        # 分别存入之前所创建的列表
        titles.append(title)
        places.append(place)
        msgs.append(msg)
        prices.append(price)
        per_meters.append(per_meter)  # json.dumps将Python对象编码成JSON字符串
        print(str(count) + ':' + json.dumps(dict, ensure_ascii=False))
    # 输出 序号：字典存储信息
    # 使用字典存储所有的信息
    datas = {
        'title': titles,
        'place': places,
        'msg': msgs,
        'price': prices,
        'per_meter': per_meters
    }
    # 通过字典的形式创建DataFrame
    # data=datas, columns=columns
    df = pd.DataFrame(datas)
    print(df)
    columns = ['title', 'place', 'msg', 'price', 'per_meter']
    df.to_csv('housetest.csv', mode='a', index=False, columns=columns)


if __name__ == '__main__':
    for i in range(1, 101):
        get_a_page(f'https://cs.ke.com/ershoufang/pg{i}')

```























